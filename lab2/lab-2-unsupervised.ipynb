{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"include_colab_link":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/raihanewubd/CSE457/blob/main/Lab_2_Unsupervised_learning_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"# Load Dataset","metadata":{"id":"CgRKihEW2XsA"}},{"cell_type":"code","source":"!gdown --id 1nLdjq_y0hJ4_A-kH6MZb9x-GDk4sNrRY","metadata":{"id":"UGp7z1Rv2XVO","outputId":"3269d897-8bf6-47a4-a55b-ad865b82223a","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:06:10.887885Z","iopub.execute_input":"2026-02-22T10:06:10.888085Z","iopub.status.idle":"2026-02-22T10:06:16.915267Z","shell.execute_reply.started":"2026-02-22T10:06:10.888061Z","shell.execute_reply":"2026-02-22T10:06:16.914287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing and Feature Engineering","metadata":{"id":"7ohh61jj2W02"}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.cluster import DBSCAN, KMeans\nfrom sklearn.metrics import silhouette_score, davies_bouldin_score\nfrom sklearn.decomposition import PCA\n\n# Load the dataset\n\ndf = pd.read_csv('adult.csv')\ndf.head()\ndf.head()","metadata":{"id":"98pwmnvFtoig","outputId":"cd4ba948-5a0e-4ee6-a983-8cc7eb737efa","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:13:30.819067Z","iopub.execute_input":"2026-02-22T10:13:30.819355Z","iopub.status.idle":"2026-02-22T10:13:30.900945Z","shell.execute_reply.started":"2026-02-22T10:13:30.819331Z","shell.execute_reply":"2026-02-22T10:13:30.900271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace '?' with NaN for handling missing values\ndf.replace(' ?', pd.NA, inplace=True)\n\n# Drop rows with missing values\ndf.dropna(inplace=True)\n\n# Drop the 'income' column as it is not needed for unsupervised learning\ndf_unsupervised = df.drop(columns=['income'])\n\n# Split the features into categorical and numerical\ncategorical_features = df_unsupervised.select_dtypes(include=['object']).columns\nnumerical_features = df_unsupervised.select_dtypes(include=['int64', 'float64']).columns\n\n# Standard scaling for numerical features only\nscaler = StandardScaler()\nscaled_numerical_data = scaler.fit_transform(df_unsupervised[numerical_features])\n\n# One-hot encoding for categorical features only\nencoder = OneHotEncoder(drop='first')\nencoded_categorical_data = encoder.fit_transform(df_unsupervised[categorical_features])\n\n# Concatenate the scaled numerical and encoded categorical data\nprocessed_data = np.hstack([scaled_numerical_data, encoded_categorical_data.toarray()])\n\n# Convert to DataFrame with appropriate column names\nfinal_columns = numerical_features.tolist() + encoder.get_feature_names_out(categorical_features).tolist()\nfinal_df = pd.DataFrame(processed_data, columns=final_columns)\n\nfinal_df.to_csv('processed_data.csv', index=False)\n\nfinal_df.head()\n","metadata":{"id":"vSOv0essrvo_","outputId":"8ae599eb-2682-48a0-c2a0-c6ac93fe4ebd","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:13:42.167156Z","iopub.execute_input":"2026-02-22T10:13:42.167502Z","iopub.status.idle":"2026-02-22T10:13:43.411304Z","shell.execute_reply.started":"2026-02-22T10:13:42.167474Z","shell.execute_reply":"2026-02-22T10:13:43.410289Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Apply Clustering","metadata":{"id":"Uo9z6YB32xGm"}},{"cell_type":"code","source":"!gdown --id 1cO2SQHvkg1SWUJgk4FU_mVx_l_NSnrn8","metadata":{"id":"GiX2AtrW1Vvx","outputId":"082b9c6a-9457-4197-bd0a-637945676837","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:13:58.053073Z","iopub.execute_input":"2026-02-22T10:13:58.053356Z","iopub.status.idle":"2026-02-22T10:14:00.947138Z","shell.execute_reply.started":"2026-02-22T10:13:58.053333Z","shell.execute_reply":"2026-02-22T10:14:00.946182Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the newly provided dataset\nfile_path = 'processed_data_adults.csv'\nprocessed_data_df = pd.read_csv(file_path)\nprocessed_data_df.head()\n\n\n# Display the first few rows to understand the structure\nprocessed_data_df.head()\n","metadata":{"id":"nLw3PB1y1c4o","outputId":"07f58830-9be1-4455-dc63-1922936d3173","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:17:26.966892Z","iopub.execute_input":"2026-02-22T10:17:26.967184Z","iopub.status.idle":"2026-02-22T10:17:27.169899Z","shell.execute_reply.started":"2026-02-22T10:17:26.967163Z","shell.execute_reply":"2026-02-22T10:17:27.168970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Elbow Method**\nThe Elbow Method can help identify the optimal number of clusters for K-Means by plotting the Within-Cluster Sum of Squares (WCSS) for different values of\nùëò\nk and looking for an \"elbow\" point where the rate of decrease sharply diminishes. This point suggests a good balance between cluster compactness and complexity.","metadata":{"id":"8A52-5kSLbYO"}},{"cell_type":"code","source":"# Calculate WCSS for a range of K values to use the Elbow Method\nwcss = []\nk_range = range(1, 11)  # Range of K values from 1 to 10\n\n# Iterate through each k and calculate WCSS\nfor k in k_range:\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(processed_data_df)\n    wcss.append(kmeans.inertia_)  # Inertia is the WCSS\n\n# Plot the Elbow graph\nplt.figure(figsize=(8, 5))\nplt.plot(k_range, wcss, marker='o', linestyle='-', color='b')\nplt.title(\"Elbow Method for Optimal K in K-Means\")\nplt.xlabel(\"Number of Clusters (K)\")\nplt.ylabel(\"Within-Cluster Sum of Squares (WCSS)\")\nplt.xticks(k_range)\nplt.show()\n","metadata":{"id":"IgHyD48nLBqv","outputId":"6628f1e5-4e79-48e3-cfe8-5f40531b2748","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:17:34.451821Z","iopub.execute_input":"2026-02-22T10:17:34.452107Z","iopub.status.idle":"2026-02-22T10:17:36.993529Z","shell.execute_reply.started":"2026-02-22T10:17:34.452087Z","shell.execute_reply":"2026-02-22T10:17:36.992695Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define number of clusters for K-Means\nn_clusters = 8\n\n# Apply K-Means clustering\nkmeans = KMeans(n_clusters=n_clusters, max_iter=30, random_state=42)\nprocessed_data_df['KMeans_Cluster'] = kmeans.fit_predict(processed_data_df)\n\n# Apply DBSCAN clustering\ndbscan = DBSCAN(eps=0.5, min_samples=5)\nprocessed_data_df['DBSCAN_Cluster'] = dbscan.fit_predict(processed_data_df)\n\n# PCA for 2D visualization\npca = PCA(n_components=2, random_state=42)\npca_result = pca.fit_transform(processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster']))\nprocessed_data_df['PCA1'] = pca_result[:, 0]\nprocessed_data_df['PCA2'] = pca_result[:, 1]\n\n# Calculate evaluation scores\ndata = processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'PCA1', 'PCA2'])\nsilhouette_kmeans = silhouette_score(data,\n                                     processed_data_df['KMeans_Cluster'])\nsilhouette_dbscan = silhouette_score(processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'PCA1', 'PCA2']),\n                                     processed_data_df['DBSCAN_Cluster'])\ndbi_kmeans = davies_bouldin_score(processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'PCA1', 'PCA2']),\n                                  processed_data_df['KMeans_Cluster'])\ndbi_dbscan = davies_bouldin_score(processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'PCA1', 'PCA2']),\n                                  processed_data_df['DBSCAN_Cluster'])\n\n# Print evaluation scores\nprint(f\"Silhouette Score (K-Means): {silhouette_kmeans}\")\nprint(f\"Silhouette Score (DBSCAN): {silhouette_dbscan}\")\nprint(f\"Davies-Bouldin Index (K-Means): {dbi_kmeans}\")\nprint(f\"Davies-Bouldin Index (DBSCAN): {dbi_dbscan}\")\n\n\n","metadata":{"id":"9jG3ZoyFDyBh","outputId":"98769913-dc12-4815-b079-1120c7c9b960","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:17:41.405176Z","iopub.execute_input":"2026-02-22T10:17:41.405455Z","iopub.status.idle":"2026-02-22T10:18:06.136237Z","shell.execute_reply.started":"2026-02-22T10:17:41.405414Z","shell.execute_reply":"2026-02-22T10:18:06.135679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**1. Silhouette Score**\n\nThe Silhouette Score measures how similar an object is to its own cluster (cohesion) compared to other clusters (separation). It ranges from -1 to +1:\n\n* +1: Indicates that samples are far from neighboring clusters, suggesting well-separated clusters.\n* 0: Indicates that samples are close to the boundary between clusters.\n* -1: Indicates that samples may have been assigned to the wrong cluster, with distances closer to other clusters than their own.\n\n**Interpretation of Your Values**\n\n* K-Means Silhouette Score: 0.117\n* DBSCAN Silhouette Score: -0.385\n\nBoth scores are negative, suggesting that samples may be closer to clusters other than their assigned ones. This generally indicates poorly separated clusters or overlap, with DBSCAN performing slightly worse here than K-Means. A higher (closer to +1) score is preferable.\n\n**2. Davies-Bouldin Index**\n\nThe Davies-Bouldin Index (DBI) assesses the average ‚Äúsimilarity‚Äù ratio of each cluster with the most similar cluster. This index is non-negative, where:\n\n* 0: Perfect score, indicating clusters are compact and well-separated.\nHigher values indicate worse clustering, with clusters that overlap or have high within-cluster spread.\n\n**Interpretation of Your Values**\n\n* K-Means DBI: 11.03\n* DBSCAN DBI: 1.53\n\nThe K-Means DBI is quite high, suggesting large overlap and poor separation. The DBSCAN score is considerably better (lower), suggesting it may have produced slightly more compact clusters.\n\n**Summary: Good vs. Bad Clustering**\n\n* Silhouette Score: Closer to +1 is better; scores near 0 or negative suggest poor clustering.\n* Davies-Bouldin Index: Lower values are better, ideally approaching 0.\nGiven these criteria:\n\nDBSCAN appears to have a better Davies-Bouldin Index, meaning the clusters are more compact and less overlapping.\nK-Means and DBSCAN both have negative Silhouette Scores, indicating the clustering structure may not be clearly defined.","metadata":{"id":"p8i83T3s4lSX"}},{"cell_type":"markdown","source":"# Visualization with PCA","metadata":{"id":"MXp2b-Sv26ME"}},{"cell_type":"code","source":"# Plot PCA visualization for K-Means and DBSCAN clusters\nplt.figure(figsize=(14, 6))\n\n# Plot for K-Means\nplt.subplot(1, 2, 1)\nsns.scatterplot(data=processed_data_df, x='PCA1', y='PCA2', hue='KMeans_Cluster', palette='viridis', s=60, alpha=0.7)\nplt.title(\"PCA Visualization of K-Means Clusters\")\nplt.xlabel(\"PCA Component 1\")\nplt.ylabel(\"PCA Component 2\")\n\n# Plot for DBSCAN\nplt.subplot(1, 2, 2)\nsns.scatterplot(data=processed_data_df, x='PCA1', y='PCA2', hue='DBSCAN_Cluster', palette='viridis', s=60, alpha=0.7)\nplt.title(\"PCA Visualization of DBSCAN Clusters\")\nplt.xlabel(\"PCA Component 1\")\nplt.ylabel(\"PCA Component 2\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"id":"ivpRAKdWED1L","outputId":"ffd6d5a3-be3d-4567-9c2d-b30b93c329df","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:18:29.483926Z","iopub.execute_input":"2026-02-22T10:18:29.484199Z","iopub.status.idle":"2026-02-22T10:18:31.680776Z","shell.execute_reply.started":"2026-02-22T10:18:29.484178Z","shell.execute_reply":"2026-02-22T10:18:31.680057Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# GMM","metadata":{"id":"qPMDmO4z3pN6"}},{"cell_type":"code","source":"from sklearn.mixture import GaussianMixture\n\n# Apply Gaussian Mixture Model with the same number of clusters as K-Means (6 clusters)\ngmm = GaussianMixture(n_components=8, random_state=42)\nprocessed_data_df['GMM_Cluster'] = gmm.fit_predict(processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'PCA1', 'PCA2']))\n\n# Calculate silhouette and Davies-Bouldin scores for GMM\nsilhouette_gmm = silhouette_score(processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'GMM_Cluster', 'PCA1', 'PCA2']),\n                                  processed_data_df['GMM_Cluster'])\ndbi_gmm = davies_bouldin_score(processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'GMM_Cluster', 'PCA1', 'PCA2']),\n                               processed_data_df['GMM_Cluster'])\n\n# Print the evaluation scores for GMM\nprint(f\"Silhouette Score (GMM): {silhouette_gmm}\")\nprint(f\"Davies-Bouldin Index (GMM): {dbi_gmm}\")\n\n# PCA visualization for GMM clusters\nplt.figure(figsize=(7, 6))\nsns.scatterplot(data=processed_data_df, x='PCA1', y='PCA2', hue='GMM_Cluster', palette='viridis', s=60, alpha=0.7)\nplt.title(\"PCA Visualization of GMM Clusters\")\nplt.xlabel(\"PCA Component 1\")\nplt.ylabel(\"PCA Component 2\")\nplt.show()\n","metadata":{"id":"hhg9rpbJ3rdj","outputId":"c2bd0816-2701-4be2-8eb5-3e689813ad26","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:18:37.860950Z","iopub.execute_input":"2026-02-22T10:18:37.861239Z","iopub.status.idle":"2026-02-22T10:18:59.777008Z","shell.execute_reply.started":"2026-02-22T10:18:37.861215Z","shell.execute_reply":"2026-02-22T10:18:59.776263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The Gaussian Mixture Model (GMM) clustering results are as follows:\n\n* Silhouette Score: 0.112, indicating weak cohesion and separation within clusters.\n* Davies-Bouldin Index: 2.39, suggesting room for improvement in cluster definition.","metadata":{"id":"N4sIH1Cl38Dp"}},{"cell_type":"markdown","source":"# Visualization using t-SNE\n(Takes ~30min to complete)","metadata":{"id":"6yfr5rKm3Ccd"}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\n\n# Apply t-SNE for 2D visualization\ntsne = TSNE(n_components=2, random_state=42)\ntsne_result = tsne.fit_transform(processed_data_df.drop(columns=['KMeans_Cluster', 'DBSCAN_Cluster', 'GMM_Cluster', 'PCA1', 'PCA2']))\n\n\n# Add t-SNE results to the DataFrame\nprocessed_data_df['tSNE1'] = tsne_result[:, 0]\nprocessed_data_df['tSNE2'] = tsne_result[:, 1]\n\n# Plot t-SNE visualization for K-Means, DBSCAN, and GMM clusters\nplt.figure(figsize=(18, 6))\n\n# Plot for K-Means\nplt.subplot(1, 3, 1)\nsns.scatterplot(data=processed_data_df, x='tSNE1', y='tSNE2', hue='KMeans_Cluster', palette='viridis', s=60, alpha=0.7)\nplt.title(\"t-SNE Visualization of K-Means Clusters\")\nplt.xlabel(\"t-SNE Component 1\")\nplt.ylabel(\"t-SNE Component 2\")\n\n# Plot for DBSCAN\nplt.subplot(1, 3, 2)\nsns.scatterplot(data=processed_data_df, x='tSNE1', y='tSNE2', hue='DBSCAN_Cluster', palette='viridis', s=60, alpha=0.7)\nplt.title(\"t-SNE Visualization of DBSCAN Clusters\")\nplt.xlabel(\"t-SNE Component 1\")\nplt.ylabel(\"t-SNE Component 2\")\n\n# Plot for GMM\nplt.subplot(1, 3, 3)\nsns.scatterplot(data=processed_data_df, x='tSNE1', y='tSNE2', hue='GMM_Cluster', palette='viridis', s=60, alpha=0.7)\nplt.title(\"t-SNE Visualization of GMM Clusters\")\nplt.xlabel(\"t-SNE Component 1\")\nplt.ylabel(\"t-SNE Component 2\")\n\nplt.tight_layout()\nplt.show()\n","metadata":{"id":"2xIT6Wu7EeEo","outputId":"700dae7c-db02-4edd-9753-6f2ee802cb4f","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:22:43.613371Z","iopub.execute_input":"2026-02-22T10:22:43.613711Z","iopub.status.idle":"2026-02-22T10:26:02.155272Z","shell.execute_reply.started":"2026-02-22T10:22:43.613687Z","shell.execute_reply":"2026-02-22T10:26:02.154204Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exercise\n\n* Apply K-NN, DBSCAN and GMM over the following dataset\n* Visualize using PCA","metadata":{"id":"FrHoUiPO18ZH"}},{"cell_type":"code","source":"!gdown --id 1Q6pdhzWFu2oegWMPvrOE8dWTra8FJsTf","metadata":{"id":"mgZEw3ZU19s-","outputId":"fa9b1cd1-59f1-4f75-cbdf-d0d73090ccee","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:28:32.102056Z","iopub.execute_input":"2026-02-22T10:28:32.102320Z","iopub.status.idle":"2026-02-22T10:28:35.222883Z","shell.execute_reply.started":"2026-02-22T10:28:32.102299Z","shell.execute_reply":"2026-02-22T10:28:35.221674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"Mall_Customers.csv\")\ndf.head()","metadata":{"id":"OSD4q6Ad2IPf","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:44:59.975412Z","iopub.execute_input":"2026-02-22T10:44:59.975721Z","iopub.status.idle":"2026-02-22T10:44:59.986516Z","shell.execute_reply.started":"2026-02-22T10:44:59.975700Z","shell.execute_reply":"2026-02-22T10:44:59.985423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans, DBSCAN\nfrom sklearn.mixture import GaussianMixture","metadata":{"id":"o-S7YhuXR37L","outputId":"7ed0c6ca-9eb1-4fc5-ba50-5c1a83383a0f","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:44:45.527287Z","iopub.execute_input":"2026-02-22T10:44:45.527552Z","iopub.status.idle":"2026-02-22T10:44:45.532009Z","shell.execute_reply.started":"2026-02-22T10:44:45.527533Z","shell.execute_reply":"2026-02-22T10:44:45.531210Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Step 3: Preprocess Data","metadata":{}},{"cell_type":"code","source":"# Drop CustomerID\ndf = df.drop(\"CustomerID\", axis=1)\n\n# Encode Gender\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf['Gender'] = le.fit_transform(df['Gender'])  # Male=1, Female=0\n\n# Scale numerical features\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndf_scaled = scaler.fit_transform(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:48:50.679149Z","iopub.execute_input":"2026-02-22T10:48:50.679425Z","iopub.status.idle":"2026-02-22T10:48:50.687568Z","shell.execute_reply.started":"2026-02-22T10:48:50.679404Z","shell.execute_reply":"2026-02-22T10:48:50.686859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"id":"flkvRsqJTN8i","trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:51:01.517131Z","iopub.execute_input":"2026-02-22T10:51:01.517388Z","iopub.status.idle":"2026-02-22T10:51:01.522383Z","shell.execute_reply.started":"2026-02-22T10:51:01.517370Z","shell.execute_reply":"2026-02-22T10:51:01.521812Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"PCA for Visualization","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\ndf_pca = pca.fit_transform(df_scaled)\ndf_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:55:39.340800Z","iopub.execute_input":"2026-02-22T10:55:39.341075Z","iopub.status.idle":"2026-02-22T10:55:39.346902Z","shell.execute_reply.started":"2026-02-22T10:55:39.341055Z","shell.execute_reply":"2026-02-22T10:55:39.346063Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"K-Means Clustering","metadata":{}},{"cell_type":"code","source":"# Reduce features to 2D for visualization\npca = PCA(n_components=2)\ndf_pca = pca.fit_transform(df_scaled)  # df_scaled from preprocessing step\n\n# Convert to DataFrame for plotting\ndf_pca = pd.DataFrame(df_pca, columns=['PC1', 'PC2'])\n\n# Add cluster labels for visualization\ndf_pca['KMeans_Cluster'] = kmeans_labels      # K-Means clusters\ndf_pca['DBSCAN_Cluster'] = dbscan_labels      # DBSCAN clusters\ndf_pca['GMM_Cluster'] = gmm_labels            # GMM clusters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:56:24.612283Z","iopub.execute_input":"2026-02-22T10:56:24.612588Z","iopub.status.idle":"2026-02-22T10:56:24.619537Z","shell.execute_reply.started":"2026-02-22T10:56:24.612563Z","shell.execute_reply":"2026-02-22T10:56:24.618653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit K-Means (choose 5 clusters as an example)\nkmeans = KMeans(n_clusters=5, random_state=42)\nkmeans_labels = kmeans.fit_predict(df_scaled)\ndf_pca['KMeans_Cluster'] = kmeans_labels\n\n# Visualize K-Means clusters\nplt.figure(figsize=(7,5))\nsns.scatterplot(x='PC1', y='PC2', hue='KMeans_Cluster', palette='Set2', data=df_pca, s=60)\nplt.title(\"K-Means Clusters (PCA)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:51:50.180681Z","iopub.execute_input":"2026-02-22T10:51:50.180975Z","iopub.status.idle":"2026-02-22T10:51:50.321788Z","shell.execute_reply.started":"2026-02-22T10:51:50.180954Z","shell.execute_reply":"2026-02-22T10:51:50.321070Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"DBSCAN Clustering","metadata":{}},{"cell_type":"code","source":"# Fit DBSCAN\ndbscan = DBSCAN(eps=1.5, min_samples=5)  # tune eps/min_samples if needed\ndbscan_labels = dbscan.fit_predict(df_scaled)\ndf_pca['DBSCAN_Cluster'] = dbscan_labels\n\n# Visualize DBSCAN clusters\nplt.figure(figsize=(7,5))\nsns.scatterplot(x='PC1', y='PC2', hue='DBSCAN_Cluster', palette='Set1', data=df_pca, s=60)\nplt.title(\"DBSCAN Clusters (PCA)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:52:19.677800Z","iopub.execute_input":"2026-02-22T10:52:19.678105Z","iopub.status.idle":"2026-02-22T10:52:19.811489Z","shell.execute_reply.started":"2026-02-22T10:52:19.678080Z","shell.execute_reply":"2026-02-22T10:52:19.810386Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"GMM Clustering","metadata":{}},{"cell_type":"code","source":"gmm = GaussianMixture(n_components=5, random_state=42)\ngmm_labels = gmm.fit_predict(df_scaled)\ndf_pca['GMM_Cluster'] = gmm_labels\n\n# Visualize GMM clusters\nplt.figure(figsize=(7,5))\nsns.scatterplot(x='PC1', y='PC2', hue='GMM_Cluster', palette='Set3', data=df_pca, s=60)\nplt.title(\"GMM Clusters (PCA)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:52:40.520351Z","iopub.execute_input":"2026-02-22T10:52:40.520744Z","iopub.status.idle":"2026-02-22T10:52:40.704157Z","shell.execute_reply.started":"2026-02-22T10:52:40.520718Z","shell.execute_reply":"2026-02-22T10:52:40.703359Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cluster Summary","metadata":{}},{"cell_type":"code","source":"# Add clusters to original dataset\ndf['KMeans_Cluster'] = kmeans_labels\ndf['DBSCAN_Cluster'] = dbscan_labels\ndf['GMM_Cluster'] = gmm_labels\n\n# Summary statistics\nprint(\"K-Means Cluster Summary:\")\nprint(df.groupby('KMeans_Cluster').mean())\nprint(\"\\nDBSCAN Cluster Summary:\")\nprint(df.groupby('DBSCAN_Cluster').mean())\nprint(\"\\nGMM Cluster Summary:\")\nprint(df.groupby('GMM_Cluster').mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T10:53:17.961777Z","iopub.execute_input":"2026-02-22T10:53:17.962080Z","iopub.status.idle":"2026-02-22T10:53:17.981054Z","shell.execute_reply.started":"2026-02-22T10:53:17.962057Z","shell.execute_reply":"2026-02-22T10:53:17.980051Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# K-Means\nkmeans_labels = kmeans.fit_predict(df_scaled)\n\n# DBSCAN\ndbscan_labels = dbscan.fit_predict(df_scaled)\n\n# GMM\ngmm_labels = gmm.fit_predict(df_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T11:04:41.393108Z","iopub.execute_input":"2026-02-22T11:04:41.393381Z","iopub.status.idle":"2026-02-22T11:04:41.424221Z","shell.execute_reply.started":"2026-02-22T11:04:41.393358Z","shell.execute_reply":"2026-02-22T11:04:41.423670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Apply PCA\npca = PCA(n_components=2)\ndf_pca_array = pca.fit_transform(df_scaled)\n\n# Convert to DataFrame\ndf_pca = pd.DataFrame(df_pca_array, columns=['PC1', 'PC2'])\n\n# Add cluster labels\ndf_pca['KMeans'] = kmeans_labels\ndf_pca['DBSCAN'] = dbscan_labels\ndf_pca['GMM'] = gmm_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T11:05:22.139854Z","iopub.execute_input":"2026-02-22T11:05:22.140204Z","iopub.status.idle":"2026-02-22T11:05:22.147520Z","shell.execute_reply.started":"2026-02-22T11:05:22.140179Z","shell.execute_reply":"2026-02-22T11:05:22.146183Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfig, axes = plt.subplots(1, 3, figsize=(21,6))\n\n# K-Means\nsns.scatterplot(\n    x='PC1', y='PC2', hue='KMeans', palette='Set2', data=df_pca, ax=axes[0], s=60\n)\naxes[0].set_title(\"K-Means Clusters (PCA)\")\n\n# DBSCAN\nsns.scatterplot(\n    x='PC1', y='PC2', hue='DBSCAN', palette='Set1', data=df_pca, ax=axes[1], s=60\n)\naxes[1].set_title(\"DBSCAN Clusters (PCA)\")\n\n# GMM\nsns.scatterplot(\n    x='PC1', y='PC2', hue='GMM', palette='Set3', data=df_pca, ax=axes[2], s=60\n)\naxes[2].set_title(\"GMM Clusters (PCA)\")\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-22T11:05:13.983815Z","iopub.execute_input":"2026-02-22T11:05:13.984141Z","iopub.status.idle":"2026-02-22T11:05:14.429907Z","shell.execute_reply.started":"2026-02-22T11:05:13.984118Z","shell.execute_reply":"2026-02-22T11:05:14.428681Z"}},"outputs":[],"execution_count":null}]}